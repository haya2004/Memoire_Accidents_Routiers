{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cccf0efe",
   "metadata": {},
   "source": [
    "# Analyse prédictive des accidents de la route\n",
    "Ce notebook présente les étapes de prétraitement des données, l'équilibrage des classes avec SMOTE, et l'entraînement de trois modèles : Régression Logistique, Random Forest et XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2575e4d8",
   "metadata": {},
   "source": [
    "## 1. Chargement des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f769f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc503e5",
   "metadata": {},
   "source": [
    "## 2. Prétraitement des données\n",
    "Supposons que le jeu de données soit déjà chargé dans `df_clean` et que la variable cible soit `gravite`. On supprime les colonnes trop révélatrices comme `nombre_deces`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbb749",
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_a_supprimer = [\"date\", \"region\", \"nombre_deces\", \"gravite\"]\n",
    "X = df_clean.drop(columns=colonnes_a_supprimer)\n",
    "y = df_clean[\"gravite\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ec44e",
   "metadata": {},
   "source": [
    "## 3. Rééquilibrage des classes avec SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64438d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f980ab",
   "metadata": {},
   "source": [
    "## 4. Séparation des données en train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3318002",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9384c",
   "metadata": {},
   "source": [
    "## 5. Entraînement et évaluation des modèles\n",
    "On applique successivement la Régression Logistique, la Forêt Aléatoire et XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fde5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Régression Logistique\n",
    "print(\"=== Régression Logistique ===\")\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "print(\"=== Random Forest ===\")\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f524870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "print(\"=== XGBoost ===\")\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa04d2c-fda1-4c81-8023-04a879c25b80",
   "metadata": {},
   "source": [
    "## 6. Analyse de Correlation \n",
    "La matrice de corrélation permet de visualiser les relations linéaires entre les variables explicatives.\n",
    "Les couleurs indiquent la force et le sens de la corrélation : le rouge foncé traduit une corrélation positive, tandis que le bleu foncé signale une corrélation négative.\n",
    "Cela permet d’identifier les variables fortement liées, comme l’âge et l’expérience du conducteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(df_clean.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Matrice de corrélation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212293a8-46d0-4337-81e9-731710ec5620",
   "metadata": {},
   "source": [
    "## 7. Deux visualisations SHAP (summary plot et force plot)\n",
    "- Le SHAP summary plot présente les variables les plus influentes dans les prédictions du modèle.\n",
    "Chaque ligne correspond à une variable, triée selon son importance, et chaque point représente une observation individuelle.\n",
    "Les points rouges indiquent des valeurs élevées qui tendent à augmenter le risque, tandis que les bleus signalent des valeurs faibles qui peuvent réduire ce risque.\n",
    "\n",
    "- Le SHAP force plot permet d’expliquer une prédiction spécifique en visualisant la contribution exacte de chaque variable.\n",
    "En rouge figurent les facteurs qui augmentent le risque d’accident grave, et en bleu ceux qui le réduisent.\n",
    "La somme de ces contributions justifie la probabilité finale attribuée par le modèle pour ce cas particulier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcdc309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(model_rf, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"dot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][0], X_test.iloc[0], matplotlib=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046dfa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SHAP Summary Plot\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "explainer = shap.Explainer(rf, X_test)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb9bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SHAP Force Plot pour une observation individuelle\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][0], X_test.iloc[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
